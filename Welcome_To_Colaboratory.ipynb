{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/seyed-mohammadreza-mousavi/Retinal-Vessel-Segmentation_A-Computer-Vision-Technique/blob/main/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-qSIIxCQb4G"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/seyed-mohammadreza-mousavi/Retinal-Vessel-Segmentation_A-Computer-Vision-Technique.git\n",
    "%cd Retinal-Vessel-Segmentation_A-Computer-Vision-Technique/ordered/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "P7GSYHT5QiCz"
   },
   "outputs": [],
   "source": [
    "%run path.py\n",
    "%run var.py\n",
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhvy7XykQoPD",
    "outputId": "c4ad131f-52cf-4388-9912-246bff1dcf2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images: 20\n",
      "number of valid/test images: 20\n",
      "number of testing images: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"number of training images:\",len(train_image_path_list))\n",
    "print(\"number of valid/test images:\",len(val_image_path_list))\n",
    "print(\"number of testing images:\",len(test_image_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsvHqtXUQp7C",
    "outputId": "fc8b2c3b-b6a4-4a85-8ed4-9ef92fa3b8b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate the training patches: 100%|██████████| 20/20 [00:25<00:00,  1.29s/it]\n",
      "Generate the val patches: 100%|██████████| 20/20 [00:26<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n",
      "['DRIVE/training/patch/26-300-img.jpg', 'DRIVE/training/patch/28-1262-img.jpg']\n",
      "['DRIVE/training/patch/26-300-groundtruth.jpg', 'DRIVE/training/patch/28-1262-groundtruth.jpg']\n",
      "['DRIVE/test/patch/01_0_val_img.jpg', 'DRIVE/test/patch/01_1000_val_img.jpg']\n",
      "['DRIVE/test/patch/01_0_val_groundtruth.jpg', 'DRIVE/test/patch/01_1000_val_groundtruth.jpg']\n"
     ]
    }
   ],
   "source": [
    "# generate train patch images\n",
    "for i in tqdm(range(len(train_image_path_list)),desc=\"Generate the training patches: \"):\n",
    "  image2patch_train(train_image_path_list[i],patch_num,patch_size,training=True,show=False)  # set show=True to visualize the sample process, which is much slower than show=False\n",
    "\n",
    "for i in tqdm(range(len(val_image_path_list)),desc=\"Generate the val patches: \"):\n",
    "  image2patch_validation(val_image_path_list[i],patch_num,patch_size,training=False,show=False)\n",
    "\n",
    "train_patch_img_path_list=sorted(glob(train_patch_dir+\"*-*-img.jpg\"))\n",
    "train_patch_groundtruth_path_list=sorted(glob(train_patch_dir+\"*-*-groundtruth.jpg\"))\n",
    "train_patch_img_path_list,train_patch_groundtruth_path_list=shuffle(train_patch_img_path_list,train_patch_groundtruth_path_list,random_state=0)\n",
    "\n",
    "val_patch_img_path_list=sorted(glob(test_patch_dir+\"*_*_val_img.jpg\"))\n",
    "val_patch_groundtruth_path_list=sorted(glob(test_patch_dir+\"*_*_val_groundtruth.jpg\"))\n",
    "\n",
    "print(len(train_patch_img_path_list),len(train_patch_groundtruth_path_list))\n",
    "print(train_patch_img_path_list[:2])\n",
    "print(train_patch_groundtruth_path_list[:2])\n",
    "\n",
    "print(val_patch_img_path_list[:2])\n",
    "print(val_patch_groundtruth_path_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "2Z0qZYy0TIUh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, AveragePooling2D, BatchNormalization, Activation, Concatenate\n",
    "\n",
    "class LinearTransform(tf.keras.layers.Layer):\n",
    "  def __init__(self, name=\"LinearTransform\", **kwargs):\n",
    "    super(LinearTransform, self).__init__(self,name=name, **kwargs)\n",
    "\n",
    "    self.conv_r=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "    self.conv_g=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "    self.conv_b=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "\n",
    "    self.pool_rc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "    self.pool_gc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "    self.pool_bc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "\n",
    "    self.bn=BatchNormalization()\n",
    "    self.sigmoid=Activation('sigmoid')\n",
    "    self.softmax=Activation('softmax')\n",
    "\n",
    "  def call(self, input,training=True):\n",
    "    r,g,b=input[:,:,:,0:1],input[:,:,:,1:2],input[:,:,:,2:3]\n",
    "\n",
    "    rs=self.conv_r(r)\n",
    "    gs=self.conv_g(g)\n",
    "    bs=self.conv_r(b)\n",
    "\n",
    "    rc=tf.reshape(self.pool_rc(rs),[-1,1])\n",
    "    gc=tf.reshape(self.pool_gc(gs),[-1,1])\n",
    "    bc=tf.reshape(self.pool_bc(bs),[-1,1])\n",
    "\n",
    "    merge=Concatenate(axis=-1)([rc,gc,bc])\n",
    "    merge=tf.expand_dims(merge,axis=1)\n",
    "    merge=tf.expand_dims(merge,axis=1)\n",
    "    merge=self.softmax(merge)\n",
    "    merge=tf.repeat(merge,repeats=patch_size,axis=2)\n",
    "    merge=tf.repeat(merge,repeats=patch_size,axis=1)\n",
    "\n",
    "    r=r*(1+self.sigmoid(rs))\n",
    "    g=g*(1+self.sigmoid(gs))\n",
    "    b=b*(1+self.sigmoid(bs))\n",
    "\n",
    "    output=self.bn(merge[:,:,:,0:1]*r+merge[:,:,:,1:2]*g+merge[:,:,:,2:3]*b,training=training)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "VmsZ4deIVPJ4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, BatchNormalization, Activation, Concatenate, LeakyReLU\n",
    "\n",
    "\n",
    "class LinearTransform(tf.keras.layers.Layer):\n",
    "    def __init__(self, name=\"LinearTransform\"):\n",
    "        super(LinearTransform, self).__init__(name=name)\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.conv_r = Conv2D(1, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.conv_g = Conv2D(1, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.conv_b = Conv2D(1, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "\n",
    "        self.pool_rc = AveragePooling2D(pool_size=(patch_size, patch_size), strides=1)\n",
    "        self.pool_gc = AveragePooling2D(pool_size=(patch_size, patch_size), strides=1)\n",
    "        self.pool_bc = AveragePooling2D(pool_size=(patch_size, patch_size), strides=1)\n",
    "\n",
    "        self.bn = BatchNormalization()\n",
    "        self.sigmoid = Activation('sigmoid')\n",
    "        self.softmax = Activation('softmax')\n",
    "\n",
    "    def call(self, input, training=True):\n",
    "        r, g, b = input[:, :, :, 0:1], input[:, :, :, 1:2], input[:, :, :, 2:3]\n",
    "\n",
    "        rs = self.conv_r(r)\n",
    "        gs = self.conv_g(g)\n",
    "        bs = self.conv_r(b)\n",
    "\n",
    "        rc = tf.reshape(self.pool_rc(rs), [-1, 1])\n",
    "        gc = tf.reshape(self.pool_gc(gs), [-1, 1])\n",
    "        bc = tf.reshape(self.pool_bc(bs), [-1, 1])\n",
    "\n",
    "        merge = Concatenate(axis=-1)([rc, gc, bc])\n",
    "        merge = tf.expand_dims(merge, axis=1)\n",
    "        merge = tf.expand_dims(merge, axis=1)\n",
    "        merge = self.softmax(merge)\n",
    "        merge = tf.repeat(merge, repeats=self.patch_size, axis=2)\n",
    "        merge = tf.repeat(merge, repeats=self.patch_size, axis=1)\n",
    "\n",
    "        r = r * (1 + self.sigmoid(rs))\n",
    "        g = g * (1 + self.sigmoid(gs))\n",
    "        b = b * (1 + self.sigmoid(bs))\n",
    "\n",
    "        output = self.bn(merge[:, :, :, 0:1] * r + merge[:, :, :, 1:2] * g + merge[:, :, :, 2:3], training=training)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(LinearTransform, self).get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fPR7YuRZA2e"
   },
   "outputs": [],
   "source": [
    "LinearTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Hiiuzu-NTlQv"
   },
   "outputs": [],
   "source": [
    "input_tensor = tf.random.normal((1, 48, 48, 3))  # Example shape, adjust according to your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjL1adR2TmC-",
    "outputId": "49204ea9-5929-474b-8903-82515b61941d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 48, 48, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearTransform()(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BFKkjT-Za5F"
   },
   "outputs": [],
   "source": [
    "LinearTransform()(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "ggrGSU1Ca2mm"
   },
   "outputs": [],
   "source": [
    "class ResBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_ch, residual_path=False, stride=1, **kwargs):\n",
    "        super(ResBlock, self).__init__(**kwargs)\n",
    "        self.residual_path = residual_path\n",
    "        self.stride = stride\n",
    "\n",
    "        self.conv1 = Conv2D(out_ch, kernel_size=3, strides=stride, padding='same', use_bias=False,\n",
    "                            data_format=\"channels_last\")\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.relu1 = LeakyReLU()\n",
    "\n",
    "        self.conv2 = Conv2D(out_ch, kernel_size=3, strides=1, padding='same', use_bias=False,\n",
    "                            data_format=\"channels_last\")\n",
    "        self.bn2 = BatchNormalization()\n",
    "\n",
    "        if residual_path:\n",
    "            self.conv_shortcut = Conv2D(out_ch, kernel_size=1, strides=stride, padding='same', use_bias=False)\n",
    "            self.bn_shortcut = BatchNormalization()\n",
    "\n",
    "        self.relu2 = LeakyReLU()\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        xs = self.relu1(self.bn1(self.conv1(x), training=training))\n",
    "        xs = self.bn2(self.conv2(xs), training=training)\n",
    "\n",
    "        if self.residual_path:\n",
    "            x = self.bn_shortcut(self.conv_shortcut(x), training=training)\n",
    "\n",
    "        xs = x + xs\n",
    "        return self.relu2(xs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ResBlock, self).get_config()\n",
    "        config.update({\"out_ch\": self.conv1.filters,\n",
    "                       \"residual_path\": self.residual_path,\n",
    "                       \"stride\": self.stride})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Un3oDjDbU4J"
   },
   "outputs": [],
   "source": [
    "ResBlock(out_ch=64, residual_path=True, stride=1)(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FYsFrVcbWi5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Concatenate, MaxPool2D, UpSampling2D\n",
    "\n",
    "\n",
    "class Unet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "\n",
    "        self.conv_init = LinearTransform()\n",
    "        self.resinit = ResBlock(16, residual_path=True)\n",
    "        self.up_sample = UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.resup = ResBlock(32, residual_path=True)\n",
    "\n",
    "        self.pool1 = MaxPool2D(pool_size=(2, 2))\n",
    "\n",
    "        self.resblock_down1 = ResBlock(64, residual_path=True)\n",
    "        self.resblock_down11 = ResBlock(64, residual_path=False)\n",
    "        self.pool2 = MaxPool2D(pool_size=(2, 2))\n",
    "\n",
    "        self.resblock_down2 = ResBlock(128, residual_path=True)\n",
    "        self.resblock_down21 = ResBlock(128, residual_path=False)\n",
    "        self.pool3 = MaxPool2D(pool_size=(2, 2))\n",
    "\n",
    "        self.resblock_down3 = ResBlock(256, residual_path=True)\n",
    "        self.resblock_down31 = ResBlock(256, residual_path=False)\n",
    "        self.pool4 = MaxPool2D(pool_size=(2, 2))\n",
    "\n",
    "        self.resblock = ResBlock(512, residual_path=True)\n",
    "\n",
    "        self.unpool3 = UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.resblock_up3 = ResBlock(256, residual_path=True)\n",
    "        self.resblock_up31 = ResBlock(256, residual_path=False)\n",
    "\n",
    "        self.unpool2 = UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.resblock_up2 = ResBlock(128, residual_path=True)\n",
    "        self.resblock_up21 = ResBlock(128, residual_path=False)\n",
    "\n",
    "        self.unpool1 = UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.resblock_up1 = ResBlock(64, residual_path=True)\n",
    "\n",
    "        self.unpool_final = UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.resblock2 = ResBlock(32, residual_path=True)\n",
    "\n",
    "        self.pool_final = MaxPool2D(pool_size=(2, 2))\n",
    "        self.resfinal = ResBlock(32)\n",
    "\n",
    "        self.conv_final = Conv2D(1, kernel_size=1, strides=1, padding='same', use_bias=False)\n",
    "        self.bn_final = BatchNormalization()\n",
    "        self.act = Activation('sigmoid')\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        x_linear = self.conv_init(x, training=training)\n",
    "        x = self.resinit(x_linear, training=training)\n",
    "        x = self.up_sample(x)\n",
    "        x = self.resup(x, training=training)\n",
    "\n",
    "        stage1 = self.pool1(x)\n",
    "        stage1 = self.resblock_down1(stage1, training=training)\n",
    "        stage1 = self.resblock_down11(stage1, training=training)\n",
    "\n",
    "        stage2 = self.pool2(stage1)\n",
    "        stage2 = self.resblock_down2(stage2, training=training)\n",
    "        stage2 = self.resblock_down21(stage2, training=training)\n",
    "\n",
    "        stage3 = self.pool3(stage2)\n",
    "        stage3 = self.resblock_down3(stage3, training=training)\n",
    "        stage3 = self.resblock_down31(stage3, training=training)\n",
    "\n",
    "        stage4 = self.pool4(stage3)\n",
    "        stage4 = self.resblock(stage4, training=training)\n",
    "\n",
    "        stage3 = Concatenate(axis=3)([stage3, self.unpool3(stage4)])\n",
    "        stage3 = self.resblock_up3(stage3, training=training)\n",
    "        stage3 = self.resblock_up31(stage3, training=training)\n",
    "\n",
    "        stage2 = Concatenate(axis=3)([stage2, self.unpool2(stage3)])\n",
    "        stage2 = self.resblock_up2(stage2, training=training)\n",
    "        stage2 = self.resblock_up21(stage2, training=training)\n",
    "\n",
    "        stage1 = Concatenate(axis=3)([stage1, self.unpool1(stage2)])\n",
    "        stage1 = self.resblock_up1(stage1, training=training)\n",
    "\n",
    "        x = Concatenate(axis=3)([x, self.unpool_final(stage1)])\n",
    "        x = self.resblock2(x, training=training)\n",
    "\n",
    "        x = self.pool_final(x)\n",
    "        x = self.resfinal(x, training=training)\n",
    "\n",
    "        seg_result = self.act(self.bn_final(self.conv_final(x), training=training))\n",
    "\n",
    "        return x_linear, seg_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JYDtNNlcBWo"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming you have defined the necessary layers and classes (LinearTransform, ResBlock, etc.)\n",
    "\n",
    "# Create an instance of the Unet model\n",
    "model = Unet()\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (256, 256, 3)  # Example input shape\n",
    "\n",
    "# Create a placeholder input tensor\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# Pass the input tensor through the Unet model\n",
    "x_linear, seg_result = model(inputs)\n",
    "\n",
    "# Create the Keras model\n",
    "keras_model = tf.keras.Model(inputs=inputs, outputs=[x_linear, seg_result])\n",
    "\n",
    "# Compile the model with an appropriate loss and optimizer\n",
    "keras_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "keras_model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Welcome To Colaboratory",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
