{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyed-mohammadreza-mousavi/Retinal-Vessel-Segmentation_A-Computer-Vision-Technique/blob/main/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/seyed-mohammadreza-mousavi/Retinal-Vessel-Segmentation_A-Computer-Vision-Technique.git\n",
        "%cd Retinal-Vessel-Segmentation_A-Computer-Vision-Technique/ordered/"
      ],
      "metadata": {
        "id": "T-qSIIxCQb4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run path.py\n",
        "%run var.py\n",
        "%run functions.py"
      ],
      "metadata": {
        "id": "P7GSYHT5QiCz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of training images:\",len(train_image_path_list))\n",
        "print(\"number of valid/test images:\",len(val_image_path_list))\n",
        "print(\"number of testing images:\",len(test_image_path_list))"
      ],
      "metadata": {
        "id": "yhvy7XykQoPD",
        "outputId": "c4ad131f-52cf-4388-9912-246bff1dcf2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training images: 20\n",
            "number of valid/test images: 20\n",
            "number of testing images: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate train patch images\n",
        "for i in tqdm(range(len(train_image_path_list)),desc=\"Generate the training patches: \"):\n",
        "  image2patch_train(train_image_path_list[i],patch_num,patch_size,training=True,show=False)  # set show=True to visualize the sample process, which is much slower than show=False\n",
        "\n",
        "for i in tqdm(range(len(val_image_path_list)),desc=\"Generate the val patches: \"):\n",
        "  image2patch_validation(val_image_path_list[i],patch_num,patch_size,training=False,show=False)\n",
        "\n",
        "train_patch_img_path_list=sorted(glob(train_patch_dir+\"*-*-img.jpg\"))\n",
        "train_patch_groundtruth_path_list=sorted(glob(train_patch_dir+\"*-*-groundtruth.jpg\"))\n",
        "train_patch_img_path_list,train_patch_groundtruth_path_list=shuffle(train_patch_img_path_list,train_patch_groundtruth_path_list,random_state=0)\n",
        "\n",
        "val_patch_img_path_list=sorted(glob(test_patch_dir+\"*_*_val_img.jpg\"))\n",
        "val_patch_groundtruth_path_list=sorted(glob(test_patch_dir+\"*_*_val_groundtruth.jpg\"))\n",
        "\n",
        "print(len(train_patch_img_path_list),len(train_patch_groundtruth_path_list))\n",
        "print(train_patch_img_path_list[:2])\n",
        "print(train_patch_groundtruth_path_list[:2])\n",
        "\n",
        "print(val_patch_img_path_list[:2])\n",
        "print(val_patch_groundtruth_path_list[:2])"
      ],
      "metadata": {
        "id": "RsvHqtXUQp7C",
        "outputId": "fc8b2c3b-b6a4-4a85-8ed4-9ef92fa3b8b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generate the training patches: 100%|██████████| 20/20 [00:25<00:00,  1.29s/it]\n",
            "Generate the val patches: 100%|██████████| 20/20 [00:26<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30000 30000\n",
            "['DRIVE/training/patch/26-300-img.jpg', 'DRIVE/training/patch/28-1262-img.jpg']\n",
            "['DRIVE/training/patch/26-300-groundtruth.jpg', 'DRIVE/training/patch/28-1262-groundtruth.jpg']\n",
            "['DRIVE/test/patch/01_0_val_img.jpg', 'DRIVE/test/patch/01_1000_val_img.jpg']\n",
            "['DRIVE/test/patch/01_0_val_groundtruth.jpg', 'DRIVE/test/patch/01_1000_val_groundtruth.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D, AveragePooling2D, BatchNormalization, Activation, Concatenate\n",
        "\n",
        "class LinearTransform(tf.keras.layers.Layer):\n",
        "  def __init__(self, name=\"LinearTransform\", **kwargs):\n",
        "    super(LinearTransform, self).__init__(self,name=name, **kwargs)\n",
        "\n",
        "    self.conv_r=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
        "    self.conv_g=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
        "    self.conv_b=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
        "\n",
        "    self.pool_rc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
        "    self.pool_gc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
        "    self.pool_bc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
        "\n",
        "    self.bn=BatchNormalization()\n",
        "    self.sigmoid=Activation('sigmoid')\n",
        "    self.softmax=Activation('softmax')\n",
        "\n",
        "  def call(self, input,training=True):\n",
        "    r,g,b=input[:,:,:,0:1],input[:,:,:,1:2],input[:,:,:,2:3]\n",
        "\n",
        "    rs=self.conv_r(r)\n",
        "    gs=self.conv_g(g)\n",
        "    bs=self.conv_r(b)\n",
        "\n",
        "    rc=tf.reshape(self.pool_rc(rs),[-1,1])\n",
        "    gc=tf.reshape(self.pool_gc(gs),[-1,1])\n",
        "    bc=tf.reshape(self.pool_bc(bs),[-1,1])\n",
        "\n",
        "    merge=Concatenate(axis=-1)([rc,gc,bc])\n",
        "    merge=tf.expand_dims(merge,axis=1)\n",
        "    merge=tf.expand_dims(merge,axis=1)\n",
        "    merge=self.softmax(merge)\n",
        "    merge=tf.repeat(merge,repeats=patch_size,axis=2)\n",
        "    merge=tf.repeat(merge,repeats=patch_size,axis=1)\n",
        "\n",
        "    r=r*(1+self.sigmoid(rs))\n",
        "    g=g*(1+self.sigmoid(gs))\n",
        "    b=b*(1+self.sigmoid(bs))\n",
        "\n",
        "    output=self.bn(merge[:,:,:,0:1]*r+merge[:,:,:,1:2]*g+merge[:,:,:,2:3]*b,training=training)\n",
        "    return output"
      ],
      "metadata": {
        "id": "2Z0qZYy0TIUh"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, BatchNormalization, Activation, Concatenate, LeakyReLU\n",
        "\n",
        "\n",
        "class LinearTransform(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=\"LinearTransform\"):\n",
        "        super(LinearTransform, self).__init__(name=name)\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.conv_r = Conv2D(1, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
        "        self.conv_g = Conv2D(1, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
        "        self.conv_b = Conv2D(1, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
        "\n",
        "        self.pool_rc = AveragePooling2D(pool_size=(patch_size, patch_size), strides=1)\n",
        "        self.pool_gc = AveragePooling2D(pool_size=(patch_size, patch_size), strides=1)\n",
        "        self.pool_bc = AveragePooling2D(pool_size=(patch_size, patch_size), strides=1)\n",
        "\n",
        "        self.bn = BatchNormalization()\n",
        "        self.sigmoid = Activation('sigmoid')\n",
        "        self.softmax = Activation('softmax')\n",
        "\n",
        "    def call(self, input, training=True):\n",
        "        r, g, b = input[:, :, :, 0:1], input[:, :, :, 1:2], input[:, :, :, 2:3]\n",
        "\n",
        "        rs = self.conv_r(r)\n",
        "        gs = self.conv_g(g)\n",
        "        bs = self.conv_r(b)\n",
        "\n",
        "        rc = tf.reshape(self.pool_rc(rs), [-1, 1])\n",
        "        gc = tf.reshape(self.pool_gc(gs), [-1, 1])\n",
        "        bc = tf.reshape(self.pool_bc(bs), [-1, 1])\n",
        "\n",
        "        merge = Concatenate(axis=-1)([rc, gc, bc])\n",
        "        merge = tf.expand_dims(merge, axis=1)\n",
        "        merge = tf.expand_dims(merge, axis=1)\n",
        "        merge = self.softmax(merge)\n",
        "        merge = tf.repeat(merge, repeats=self.patch_size, axis=2)\n",
        "        merge = tf.repeat(merge, repeats=self.patch_size, axis=1)\n",
        "\n",
        "        r = r * (1 + self.sigmoid(rs))\n",
        "        g = g * (1 + self.sigmoid(gs))\n",
        "        b = b * (1 + self.sigmoid(bs))\n",
        "\n",
        "        output = self.bn(merge[:, :, :, 0:1] * r + merge[:, :, :, 1:2] * g + merge[:, :, :, 2:3], training=training)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(LinearTransform, self).get_config()\n",
        "        config.update({\"patch_size\": self.patch_size})\n",
        "        return config"
      ],
      "metadata": {
        "id": "VmsZ4deIVPJ4"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LinearTransform()"
      ],
      "metadata": {
        "id": "0fPR7YuRZA2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = tf.random.normal((1, 48, 48, 3))  # Example shape, adjust according to your needs"
      ],
      "metadata": {
        "id": "Hiiuzu-NTlQv"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LinearTransform()(input_tensor).shape"
      ],
      "metadata": {
        "id": "DjL1adR2TmC-",
        "outputId": "49204ea9-5929-474b-8903-82515b61941d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 48, 48, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LinearTransform()(input_tensor)"
      ],
      "metadata": {
        "id": "2BFKkjT-Za5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, out_ch, residual_path=False, stride=1, **kwargs):\n",
        "        super(ResBlock, self).__init__(**kwargs)\n",
        "        self.residual_path = residual_path\n",
        "        self.stride = stride\n",
        "\n",
        "        self.conv1 = Conv2D(out_ch, kernel_size=3, strides=stride, padding='same', use_bias=False,\n",
        "                            data_format=\"channels_last\")\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.relu1 = LeakyReLU()\n",
        "\n",
        "        self.conv2 = Conv2D(out_ch, kernel_size=3, strides=1, padding='same', use_bias=False,\n",
        "                            data_format=\"channels_last\")\n",
        "        self.bn2 = BatchNormalization()\n",
        "\n",
        "        if residual_path:\n",
        "            self.conv_shortcut = Conv2D(out_ch, kernel_size=1, strides=stride, padding='same', use_bias=False)\n",
        "            self.bn_shortcut = BatchNormalization()\n",
        "\n",
        "        self.relu2 = LeakyReLU()\n",
        "\n",
        "    def call(self, x, training=True):\n",
        "        xs = self.relu1(self.bn1(self.conv1(x), training=training))\n",
        "        xs = self.bn2(self.conv2(xs), training=training)\n",
        "\n",
        "        if self.residual_path:\n",
        "            x = self.bn_shortcut(self.conv_shortcut(x), training=training)\n",
        "\n",
        "        xs = x + xs\n",
        "        return self.relu2(xs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(ResBlock, self).get_config()\n",
        "        config.update({\"out_ch\": self.conv1.filters,\n",
        "                       \"residual_path\": self.residual_path,\n",
        "                       \"stride\": self.stride})\n",
        "        return config"
      ],
      "metadata": {
        "id": "ggrGSU1Ca2mm"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResBlock(out_ch=64, residual_path=True, stride=1)(input_tensor)"
      ],
      "metadata": {
        "id": "-Un3oDjDbU4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Concatenate, MaxPool2D, UpSampling2D\n",
        "\n",
        "\n",
        "class Unet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Unet, self).__init__()\n",
        "\n",
        "        self.conv_init = LinearTransform()\n",
        "        self.resinit = ResBlock(16, residual_path=True)\n",
        "        self.up_sample = UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
        "        self.resup = ResBlock(32, residual_path=True)\n",
        "\n",
        "        self.pool1 = MaxPool2D(pool_size=(2, 2))\n",
        "\n",
        "        self.resblock_down1 = ResBlock(64, residual_path=True)\n",
        "        self.resblock_down11 = ResBlock(64, residual_path=False)\n",
        "        self.pool2 = MaxPool2D(pool_size=(2, 2))\n",
        "\n",
        "        self.resblock_down2 = ResBlock(128, residual_path=True)\n",
        "        self.resblock_down21 = ResBlock(128, residual_path=False)\n",
        "        self.pool3 = MaxPool2D(pool_size=(2, 2))\n",
        "\n",
        "        self.resblock_down3 = ResBlock(256, residual_path=True)\n",
        "        self.resblock_down31 = ResBlock(256, residual_path=False)\n",
        "        self.pool4 = MaxPool2D(pool_size=(2, 2))\n",
        "\n",
        "        self.resblock = ResBlock(512, residual_path=True)\n",
        "\n",
        "        self.unpool3 = UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
        "        self.resblock_up3 = ResBlock(256, residual_path=True)\n",
        "        self.resblock_up31 = ResBlock(256, residual_path=False)\n",
        "\n",
        "        self.unpool2 = UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
        "        self.resblock_up2 = ResBlock(128, residual_path=True)\n",
        "        self.resblock_up21 = ResBlock(128, residual_path=False)\n",
        "\n",
        "        self.unpool1 = UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
        "        self.resblock_up1 = ResBlock(64, residual_path=True)\n",
        "\n",
        "        self.unpool_final = UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
        "        self.resblock2 = ResBlock(32, residual_path=True)\n",
        "\n",
        "        self.pool_final = MaxPool2D(pool_size=(2, 2))\n",
        "        self.resfinal = ResBlock(32)\n",
        "\n",
        "        self.conv_final = Conv2D(1, kernel_size=1, strides=1, padding='same', use_bias=False)\n",
        "        self.bn_final = BatchNormalization()\n",
        "        self.act = Activation('sigmoid')\n",
        "\n",
        "    def call(self, x, training=True):\n",
        "        x_linear = self.conv_init(x, training=training)\n",
        "        x = self.resinit(x_linear, training=training)\n",
        "        x = self.up_sample(x)\n",
        "        x = self.resup(x, training=training)\n",
        "\n",
        "        stage1 = self.pool1(x)\n",
        "        stage1 = self.resblock_down1(stage1, training=training)\n",
        "        stage1 = self.resblock_down11(stage1, training=training)\n",
        "\n",
        "        stage2 = self.pool2(stage1)\n",
        "        stage2 = self.resblock_down2(stage2, training=training)\n",
        "        stage2 = self.resblock_down21(stage2, training=training)\n",
        "\n",
        "        stage3 = self.pool3(stage2)\n",
        "        stage3 = self.resblock_down3(stage3, training=training)\n",
        "        stage3 = self.resblock_down31(stage3, training=training)\n",
        "\n",
        "        stage4 = self.pool4(stage3)\n",
        "        stage4 = self.resblock(stage4, training=training)\n",
        "\n",
        "        stage3 = Concatenate(axis=3)([stage3, self.unpool3(stage4)])\n",
        "        stage3 = self.resblock_up3(stage3, training=training)\n",
        "        stage3 = self.resblock_up31(stage3, training=training)\n",
        "\n",
        "        stage2 = Concatenate(axis=3)([stage2, self.unpool2(stage3)])\n",
        "        stage2 = self.resblock_up2(stage2, training=training)\n",
        "        stage2 = self.resblock_up21(stage2, training=training)\n",
        "\n",
        "        stage1 = Concatenate(axis=3)([stage1, self.unpool1(stage2)])\n",
        "        stage1 = self.resblock_up1(stage1, training=training)\n",
        "\n",
        "        x = Concatenate(axis=3)([x, self.unpool_final(stage1)])\n",
        "        x = self.resblock2(x, training=training)\n",
        "\n",
        "        x = self.pool_final(x)\n",
        "        x = self.resfinal(x, training=training)\n",
        "\n",
        "        seg_result = self.act(self.bn_final(self.conv_final(x), training=training))\n",
        "\n",
        "        return x_linear, seg_result"
      ],
      "metadata": {
        "id": "2FYsFrVcbWi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assuming you have defined the necessary layers and classes (LinearTransform, ResBlock, etc.)\n",
        "\n",
        "# Create an instance of the Unet model\n",
        "model = Unet()\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (256, 256, 3)  # Example input shape\n",
        "\n",
        "# Create a placeholder input tensor\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# Pass the input tensor through the Unet model\n",
        "x_linear, seg_result = model(inputs)\n",
        "\n",
        "# Create the Keras model\n",
        "keras_model = tf.keras.Model(inputs=inputs, outputs=[x_linear, seg_result])\n",
        "\n",
        "# Compile the model with an appropriate loss and optimizer\n",
        "keras_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the model\n",
        "keras_model.fit(x_train, y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "1JYDtNNlcBWo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}