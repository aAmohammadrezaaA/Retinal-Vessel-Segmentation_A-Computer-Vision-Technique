{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyed-mohammadreza-mousavi/Retinal-Vessel-Segmentation_A-Computer-Vision-Technique/blob/main/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQIi2AGTTHis",
        "outputId": "f9150268-d6d7-4b2b-d619-793b535bd00e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (2.13.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhFvpjLxTJmC",
        "outputId": "3e96eeb2-3346-4ec2-fa55-d93881a53b29"
      },
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘images’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/alireza.jpg -P images\n",
        "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/ali.jpg -P images\n",
        "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/mohsen.jpg -P images\n",
        "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/muhammad.jpg -P images\n",
        "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/1.jpg -P images\n",
        "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/srttu-class.png -P images\n",
        "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/m_wrapped.png -P images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOURV-12TOGo",
        "outputId": "2bd65b16-22d2-48cb-e928-0859d47b45bd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-20 10:35:28--  https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/alireza.jpg\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/alireza.jpg [following]\n",
            "--2023-10-20 10:35:28--  https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/alireza.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39450 (39K) [image/jpeg]\n",
            "Saving to: ‘images/alireza.jpg.1’\n",
            "\n",
            "alireza.jpg.1       100%[===================>]  38.53K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2023-10-20 10:35:28 (6.20 MB/s) - ‘images/alireza.jpg.1’ saved [39450/39450]\n",
            "\n",
            "--2023-10-20 10:35:28--  https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/ali.jpg\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/ali.jpg [following]\n",
            "--2023-10-20 10:35:29--  https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/ali.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56889 (56K) [image/jpeg]\n",
            "Saving to: ‘images/ali.jpg.1’\n",
            "\n",
            "ali.jpg.1           100%[===================>]  55.56K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2023-10-20 10:35:29 (6.06 MB/s) - ‘images/ali.jpg.1’ saved [56889/56889]\n",
            "\n",
            "--2023-10-20 10:35:29--  https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/mohsen.jpg\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/mohsen.jpg [following]\n",
            "--2023-10-20 10:35:29--  https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/mohsen.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31528 (31K) [image/jpeg]\n",
            "Saving to: ‘images/mohsen.jpg.1’\n",
            "\n",
            "mohsen.jpg.1        100%[===================>]  30.79K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-10-20 10:35:29 (4.30 MB/s) - ‘images/mohsen.jpg.1’ saved [31528/31528]\n",
            "\n",
            "--2023-10-20 10:35:29--  https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/muhammad.jpg\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/muhammad.jpg [following]\n",
            "--2023-10-20 10:35:30--  https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/muhammad.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 78137 (76K) [image/jpeg]\n",
            "Saving to: ‘images/muhammad.jpg.1’\n",
            "\n",
            "muhammad.jpg.1      100%[===================>]  76.31K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-10-20 10:35:30 (5.14 MB/s) - ‘images/muhammad.jpg.1’ saved [78137/78137]\n",
            "\n",
            "--2023-10-20 10:35:30--  https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/1.jpg\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/1.jpg [following]\n",
            "--2023-10-20 10:35:30--  https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/1.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13806 (13K) [image/jpeg]\n",
            "Saving to: ‘images/1.jpg.1’\n",
            "\n",
            "1.jpg.1             100%[===================>]  13.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-20 10:35:31 (38.4 MB/s) - ‘images/1.jpg.1’ saved [13806/13806]\n",
            "\n",
            "--2023-10-20 10:35:31--  https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/srttu-class.png\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/srttu-class.png [following]\n",
            "--2023-10-20 10:35:31--  https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/images/srttu-class.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 836501 (817K) [image/png]\n",
            "Saving to: ‘images/srttu-class.png.1’\n",
            "\n",
            "srttu-class.png.1   100%[===================>] 816.90K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-10-20 10:35:31 (25.0 MB/s) - ‘images/srttu-class.png.1’ saved [836501/836501]\n",
            "\n",
            "--2023-10-20 10:35:31--  https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/m_wrapped.png\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2023-10-20 10:35:32 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/ArcFace.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OCo-y-sTQ5R",
        "outputId": "21620809-a8d5-4afd-d58a-f152e7815f2c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-20 10:35:32--  https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/ArcFace.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4043 (3.9K) [text/plain]\n",
            "Saving to: ‘ArcFace.py.1’\n",
            "\n",
            "ArcFace.py.1        100%[===================>]   3.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-20 10:35:32 (15.6 MB/s) - ‘ArcFace.py.1’ saved [4043/4043]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ArcFace\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "RaQ4V-wUTTKn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/yaledhlab/vggface.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXKglz4aUNDj",
        "outputId": "185c8be3-7bc4-47d4-a4d8-0f23d868aae1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/yaledhlab/vggface.git\n",
            "  Cloning https://github.com/yaledhlab/vggface.git to /tmp/pip-req-build-_z_s3zx3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/yaledhlab/vggface.git /tmp/pip-req-build-_z_s3zx3\n",
            "  Resolved https://github.com/yaledhlab/vggface.git to commit b76539b7588bca69b0030ad7e4f985f877dc7c0a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (1.11.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (3.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (9.4.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (2.13.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_applications"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXDseKmiUSuj",
        "outputId": "a106bfd4-6f97-4972-c915-e6eb9b847b15"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_applications) (1.23.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_applications) (3.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_vggface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSUdlXsNVT8-",
        "outputId": "aa261f19-46be-46ea-e0fe-6db2141a8c30"
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_vggface in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.11.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (3.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (9.4.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (2.13.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of face detection with a vggface2 model\n",
        "from numpy import expand_dims\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.utils import decode_predictions"
      ],
      "metadata": {
        "id": "Ddf0VZfEVVnW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/ajb.jpg -P images"
      ],
      "metadata": {
        "id": "lhHYV8FPVu_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras import backend\n",
        "from tensorflow.python.keras.engine import training\n",
        "from tensorflow.python.keras.utils import data_utils\n",
        "from tensorflow.python.keras.utils import layer_utils\n",
        "from tensorflow.python.lib.io import file_io\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import gdown\n",
        "\n",
        "def loadModel():\n",
        "\tbase_model = ResNet34()\n",
        "\tinputs = base_model.inputs[0]\n",
        "\tarcface_model = base_model.outputs[0]\n",
        "\tarcface_model = keras.layers.BatchNormalization(momentum=0.9, epsilon=2e-5)(arcface_model)\n",
        "\tarcface_model = keras.layers.Dropout(0.4)(arcface_model)\n",
        "\tarcface_model = keras.layers.Flatten()(arcface_model)\n",
        "\tarcface_model = keras.layers.Dense(512, activation=None, use_bias=True, kernel_initializer=\"glorot_normal\")(arcface_model)\n",
        "\tembedding = keras.layers.BatchNormalization(momentum=0.9, epsilon=2e-5, name=\"embedding\", scale=True)(arcface_model)\n",
        "\tmodel = keras.models.Model(inputs, embedding, name=base_model.name)\n",
        "\n",
        "\t#---------------------------------------\n",
        "\t#check the availability of pre-trained weights\n",
        "\n",
        "\thome = str(Path.home())\n",
        "\n",
        "\turl = \"https://drive.google.com/uc?id=1LVB3CdVejpmGHM28BpqqkbZP5hDEcdZY\"\n",
        "\tfile_name = \"arcface_weights.h5\"\n",
        "\toutput = home+'/.deepface/weights/'+file_name\n",
        "\tPath(home+'/.deepface/weights/').mkdir(parents=True, exist_ok=True)\n",
        "\tif os.path.isfile(output) != True:\n",
        "\n",
        "\t\tprint(file_name,\" will be downloaded to \",output)\n",
        "\t\tgdown.download(url, output, quiet=False)\n",
        "\n",
        "\t#---------------------------------------\n",
        "\n",
        "\ttry:\n",
        "\t\tmodel.load_weights(output)\n",
        "\texcept:\n",
        "\t\tprint(\"pre-trained weights could not be loaded.\")\n",
        "\t\tprint(\"You might try to download it from the url \", url,\" and copy to \",output,\" manually\")\n",
        "\n",
        "\treturn model\n",
        "\n",
        "def ResNet34():\n",
        "\n",
        "\timg_input = tensorflow.keras.layers.Input(shape=(112, 112, 3))\n",
        "\n",
        "\tx = tensorflow.keras.layers.ZeroPadding2D(padding=1, name='conv1_pad')(img_input)\n",
        "\tx = tensorflow.keras.layers.Conv2D(64, 3, strides=1, use_bias=False, kernel_initializer='glorot_normal', name='conv1_conv')(x)\n",
        "\tx = tensorflow.keras.layers.BatchNormalization(axis=3, epsilon=2e-5, momentum=0.9, name='conv1_bn')(x)\n",
        "\tx = tensorflow.keras.layers.PReLU(shared_axes=[1, 2], name='conv1_prelu')(x)\n",
        "\tx = stack_fn(x)\n",
        "\n",
        "\tmodel = training.Model(img_input, x, name='ResNet34')\n",
        "\n",
        "\treturn model\n",
        "\n",
        "def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n",
        "\tbn_axis = 3\n",
        "\n",
        "\tif conv_shortcut:\n",
        "\t\tshortcut = tensorflow.keras.layers.Conv2D(filters, 1, strides=stride, use_bias=False, kernel_initializer='glorot_normal', name=name + '_0_conv')(x)\n",
        "\t\tshortcut = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_0_bn')(shortcut)\n",
        "\telse:\n",
        "\t\tshortcut = x\n",
        "\n",
        "\tx = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_1_bn')(x)\n",
        "\tx = tensorflow.keras.layers.ZeroPadding2D(padding=1, name=name + '_1_pad')(x)\n",
        "\tx = tensorflow.keras.layers.Conv2D(filters, 3, strides=1, kernel_initializer='glorot_normal', use_bias=False, name=name + '_1_conv')(x)\n",
        "\tx = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_2_bn')(x)\n",
        "\tx = tensorflow.keras.layers.PReLU(shared_axes=[1, 2], name=name + '_1_prelu')(x)\n",
        "\n",
        "\tx = tensorflow.keras.layers.ZeroPadding2D(padding=1, name=name + '_2_pad')(x)\n",
        "\tx = tensorflow.keras.layers.Conv2D(filters, kernel_size, strides=stride, kernel_initializer='glorot_normal', use_bias=False, name=name + '_2_conv')(x)\n",
        "\tx = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_3_bn')(x)\n",
        "\n",
        "\tx = tensorflow.keras.layers.Add(name=name + '_add')([shortcut, x])\n",
        "\treturn x\n",
        "\n",
        "def stack1(x, filters, blocks, stride1=2, name=None):\n",
        "\tx = block1(x, filters, stride=stride1, name=name + '_block1')\n",
        "\tfor i in range(2, blocks + 1):\n",
        "\t\tx = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))\n",
        "\treturn x\n",
        "\n",
        "def stack_fn(x):\n",
        "\tx = stack1(x, 64, 3, name='conv2')\n",
        "\tx = stack1(x, 128, 4, name='conv3')\n",
        "\tx = stack1(x, 256, 6, name='conv4')\n",
        "\treturn stack1(x, 512, 3, name='conv5')"
      ],
      "metadata": {
        "id": "Uzj5e6zBXKaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=loadModel()"
      ],
      "metadata": {
        "id": "Raq6omkwXRQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGGFace()"
      ],
      "metadata": {
        "id": "se98CSwNWyhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ArcFace.loadModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB98AQXzVoua",
        "outputId": "2577c0c7-c2a3-4a2f-fb52-5e8a6d5f43e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arcface_weights.h5  will be downloaded to  /root/.deepface/weights/arcface_weights.h5\n",
            "Access denied with the following error:\n",
            "pre-trained weights could not be loaded.\n",
            "You might try to download it from the url  https://drive.google.com/uc?id=1LVB3CdVejpmGHM28BpqqkbZP5hDEcdZY  and copy to  /root/.deepface/weights/arcface_weights.h5  manually\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1LVB3CdVejpmGHM28BpqqkbZP5hDEcdZY \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_detector = MTCNN()"
      ],
      "metadata": {
        "id": "Spjhbv7RTUy4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the image path with yours.\n",
        "img = image.load_img('./images/ajb.jpg', target_size=(224, 224))\n",
        "img"
      ],
      "metadata": {
        "id": "2V1OxKkAVynB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_face(img):\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #mtcnn expects RGB but OpenCV read BGR\n",
        "    detections = face_detector.detect_faces(img_rgb)\n",
        "    detection = detections[0]\n",
        "    x, y, w, h = detection[\"box\"]\n",
        "    detected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
        "    return detected_face"
      ],
      "metadata": {
        "id": "Fjfvd0L-TWIx"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_face(img, target_size=(112,112)):\n",
        "    img = cv2.imread(img)\n",
        "    img = detect_face(img)\n",
        "    img = cv2.resize(img, target_size)\n",
        "    img_pixels = image.img_to_array(img)\n",
        "    img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "    img_pixels /= 255 #normalize input in [0, 1]\n",
        "    return img_pixels"
      ],
      "metadata": {
        "id": "vCAcBjBlTYJY"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_to_encoding(path):\n",
        "    img = preprocess_face(path)\n",
        "    return model.predict(img)[0]"
      ],
      "metadata": {
        "id": "WKHKJa1CTZoQ"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "database = {}\n",
        "\n",
        "database[\"alireza\"] = img_to_encoding(\"./images/alireza.jpg\")\n",
        "database[\"ali\"] = img_to_encoding(\"./images/ali.jpg\")\n",
        "database[\"mohsen\"] = img_to_encoding(\"./images/mohsen.jpg\")\n",
        "database[\"muhammad\"] = img_to_encoding(\"./images/muhammad.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io-Vl7I_TbKY",
        "outputId": "4e928be8-f335-432f-c9cc-7e01a600dbd8"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 195ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 163ms/step\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "1/1 [==============================] - 0s 293ms/step\n",
            "1/1 [==============================] - 0s 169ms/step\n",
            "3/3 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 204ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 201ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def EuclideanDistance(source_representation, test_representation):\n",
        "    euclidean_distance = source_representation - test_representation\n",
        "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
        "    euclidean_distance = np.sqrt(euclidean_distance)\n",
        "    return euclidean_distance"
      ],
      "metadata": {
        "id": "pfQ7ymMcTcYj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verification_threshhold = 4.4"
      ],
      "metadata": {
        "id": "SScYDFdpTffT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify(image_path, identity, database):\n",
        "    # Step 1: Compute the encoding for the image. Use img_to_encoding()\n",
        "    encoding = img_to_encoding(image_path)\n",
        "\n",
        "    # Step 2: Compute distance with identity's image\n",
        "    dist = EuclideanDistance(encoding, database[identity])\n",
        "\n",
        "    # Step 3: Open the door if dist < verification_threshhold, else don't open\n",
        "    if dist < verification_threshhold:\n",
        "        print(\"It's \" + str(identity) + \", welcome!\")\n",
        "    else:\n",
        "        print(\"It's not \" + str(identity) + \", please go away\")\n",
        "\n",
        "    return dist"
      ],
      "metadata": {
        "id": "It5ECibtThCP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepface"
      ],
      "metadata": {
        "id": "X4BbAa7vq0Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace"
      ],
      "metadata": {
        "id": "mSJahX62q2zU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\", \"SFace\",]"
      ],
      "metadata": {
        "id": "3Nrobil1rCEv"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = DeepFace.verify(img1_path = \"images/1.jpg\", img2_path = \"images/alireza.jpg\", model_name = models[0])"
      ],
      "metadata": {
        "id": "8Q3NxV8Xq6t9"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = DeepFace.find(img_path = \"images/mohsen.jpg\", db_path = \"images/\")"
      ],
      "metadata": {
        "id": "N-pO-Z0J3X97",
        "outputId": "8203f7e1-fcb8-4933-f227-b4664fc58491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Representations for images in images/ folder were previously stored in representations_vgg_face.pkl. If you added new instances after the creation, then please delete this file and call find function again. It will create it again.\n",
            "There are  13  representations found in  representations_vgg_face.pkl\n",
            "find function lasts  0.9238824844360352  seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_objs = DeepFace.represent(img_path = \"images/mohsen.jpg\")"
      ],
      "metadata": {
        "id": "vBYO1wNp4fD5"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = embedding_objs[0][\"embedding\"]"
      ],
      "metadata": {
        "id": "8Ko75jdc5Ecf"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding"
      ],
      "metadata": {
        "id": "O2H6Y2pt5Ngi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs"
      ],
      "metadata": {
        "id": "sBLEZ7WV3n6Z",
        "outputId": "43c72b79-794e-4712-a2ad-cf723c274bb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[               identity  source_x  source_y  source_w  source_h  \\\n",
              " 0  images//mohsen.jpg.1       201       119       367       367   \n",
              " 1    images//mohsen.jpg       201       119       367       367   \n",
              " \n",
              "    VGG-Face_cosine  \n",
              " 0     1.110223e-15  \n",
              " 1     1.110223e-15  ]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "p9jxhkuR2LOr",
        "outputId": "e5b81143-3953-46df-e603-38e129267d9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'verified': True,\n",
              " 'distance': 0.2715841925972273,\n",
              " 'threshold': 0.4,\n",
              " 'model': 'VGG-Face',\n",
              " 'detector_backend': 'opencv',\n",
              " 'similarity_metric': 'cosine',\n",
              " 'facial_areas': {'img1': {'x': 38, 'y': 18, 'w': 178, 'h': 178},\n",
              "  'img2': {'x': 189, 'y': 141, 'w': 212, 'h': 212}},\n",
              " 'time': 1.59}"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.get(\"distance\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP_wav_prVST",
        "outputId": "3b6b103c-5cb3-4c3f-d239-fc54472152eb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2715841925972273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database"
      ],
      "metadata": {
        "id": "CGNSnZLF2UhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verify(\"images/1.jpg\", \"alireza\", database)"
      ],
      "metadata": {
        "id": "bByRZMKTTi0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verify(\"images/ali.jpg\", \"alireza\", database)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfqhxLvSTq0I",
        "outputId": "85f5478f-fa0c-4379-c3cd-7e7baec26ef1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 1s 537ms/step\n",
            "It's alireza, welcome!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00023055093"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "joYGpynPh6Lz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}