{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyed-mohammadreza-mousavi/Retinal-Vessel-Segmentation_A-Computer-Vision-Technique/blob/main/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "id": "Ap6QEH5u81M1",
        "outputId": "a841d824-5b2d-411d-c16b-4f98314fb7d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (2.13.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.23.5)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ArcFace"
      ],
      "metadata": {
        "id": "QUg2UXoP89Jv",
        "outputId": "49a4c953-e888-4c6f-e7bd-d8b3e9013afb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ArcFace\n",
            "  Downloading arcface-0.0.8-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from ArcFace) (2.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from ArcFace) (6.0.1)\n",
            "Requirement already satisfied: opencv-python>=4.4 in /usr/local/lib/python3.10/dist-packages (from ArcFace) (4.8.0.76)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ArcFace) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ArcFace) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->ArcFace) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->ArcFace) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->ArcFace) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->ArcFace) (2023.7.22)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3.0->ArcFace) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.3.0->ArcFace) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (3.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.3.0->ArcFace) (3.2.2)\n",
            "Installing collected packages: ArcFace\n",
            "Successfully installed ArcFace-0.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras import backend\n",
        "from tensorflow.python.keras.engine import training\n",
        "from tensorflow.python.keras.utils import data_utils\n",
        "from tensorflow.python.keras.utils import layer_utils\n",
        "from tensorflow.python.lib.io import file_io\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import gdown\n",
        "\n",
        "def loadModel():\n",
        "\tbase_model = ResNet34()\n",
        "\tinputs = base_model.inputs[0]\n",
        "\tarcface_model = base_model.outputs[0]\n",
        "\tarcface_model = keras.layers.BatchNormalization(momentum=0.9, epsilon=2e-5)(arcface_model)\n",
        "\tarcface_model = keras.layers.Dropout(0.4)(arcface_model)\n",
        "\tarcface_model = keras.layers.Flatten()(arcface_model)\n",
        "\tarcface_model = keras.layers.Dense(512, activation=None, use_bias=True, kernel_initializer=\"glorot_normal\")(arcface_model)\n",
        "\tembedding = keras.layers.BatchNormalization(momentum=0.9, epsilon=2e-5, name=\"embedding\", scale=True)(arcface_model)\n",
        "\tmodel = keras.models.Model(inputs, embedding, name=base_model.name)\n",
        "\n",
        "\t#---------------------------------------\n",
        "\t#check the availability of pre-trained weights\n",
        "\n",
        "\thome = str(Path.home())\n",
        "\n",
        "\turl = \"https://drive.google.com/uc?id=1LVB3CdVejpmGHM28BpqqkbZP5hDEcdZY\"\n",
        "\tfile_name = \"arcface_weights.h5\"\n",
        "\toutput = home+'/.deepface/weights/'+file_name\n",
        "\tPath(home+'/.deepface/weights/').mkdir(parents=True, exist_ok=True)\n",
        "\tif os.path.isfile(output) != True:\n",
        "\n",
        "\t\tprint(file_name,\" will be downloaded to \",output)\n",
        "\t\tgdown.download(url, output, quiet=False)\n",
        "\n",
        "\t#---------------------------------------\n",
        "\n",
        "\ttry:\n",
        "\t\tmodel.load_weights(output)\n",
        "\texcept:\n",
        "\t\tprint(\"pre-trained weights could not be loaded.\")\n",
        "\t\tprint(\"You might try to download it from the url \", url,\" and copy to \",output,\" manually\")\n",
        "\n",
        "\treturn model\n",
        "\n",
        "def ResNet34():\n",
        "\n",
        "\timg_input = tensorflow.keras.layers.Input(shape=(112, 112, 3))\n",
        "\n",
        "\tx = tensorflow.keras.layers.ZeroPadding2D(padding=1, name='conv1_pad')(img_input)\n",
        "\tx = tensorflow.keras.layers.Conv2D(64, 3, strides=1, use_bias=False, kernel_initializer='glorot_normal', name='conv1_conv')(x)\n",
        "\tx = tensorflow.keras.layers.BatchNormalization(axis=3, epsilon=2e-5, momentum=0.9, name='conv1_bn')(x)\n",
        "\tx = tensorflow.keras.layers.PReLU(shared_axes=[1, 2], name='conv1_prelu')(x)\n",
        "\tx = stack_fn(x)\n",
        "\n",
        "\tmodel = training.Model(img_input, x, name='ResNet34')\n",
        "\n",
        "\treturn model\n",
        "\n",
        "def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n",
        "\tbn_axis = 3\n",
        "\n",
        "\tif conv_shortcut:\n",
        "\t\tshortcut = tensorflow.keras.layers.Conv2D(filters, 1, strides=stride, use_bias=False, kernel_initializer='glorot_normal', name=name + '_0_conv')(x)\n",
        "\t\tshortcut = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_0_bn')(shortcut)\n",
        "\telse:\n",
        "\t\tshortcut = x\n",
        "\n",
        "\tx = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_1_bn')(x)\n",
        "\tx = tensorflow.keras.layers.ZeroPadding2D(padding=1, name=name + '_1_pad')(x)\n",
        "\tx = tensorflow.keras.layers.Conv2D(filters, 3, strides=1, kernel_initializer='glorot_normal', use_bias=False, name=name + '_1_conv')(x)\n",
        "\tx = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_2_bn')(x)\n",
        "\tx = tensorflow.keras.layers.PReLU(shared_axes=[1, 2], name=name + '_1_prelu')(x)\n",
        "\n",
        "\tx = tensorflow.keras.layers.ZeroPadding2D(padding=1, name=name + '_2_pad')(x)\n",
        "\tx = tensorflow.keras.layers.Conv2D(filters, kernel_size, strides=stride, kernel_initializer='glorot_normal', use_bias=False, name=name + '_2_conv')(x)\n",
        "\tx = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_3_bn')(x)\n",
        "\n",
        "\tx = tensorflow.keras.layers.Add(name=name + '_add')([shortcut, x])\n",
        "\treturn x\n",
        "\n",
        "def stack1(x, filters, blocks, stride1=2, name=None):\n",
        "\tx = block1(x, filters, stride=stride1, name=name + '_block1')\n",
        "\tfor i in range(2, blocks + 1):\n",
        "\t\tx = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))\n",
        "\treturn x\n",
        "\n",
        "def stack_fn(x):\n",
        "\tx = stack1(x, 64, 3, name='conv2')\n",
        "\tx = stack1(x, 128, 4, name='conv3')\n",
        "\tx = stack1(x, 256, 6, name='conv4')\n",
        "\treturn stack1(x, 512, 3, name='conv5')"
      ],
      "metadata": {
        "id": "GV8q6X3D9FUd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mtcnn.mtcnn import MTCNN\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "a9Wm7aT181Kh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = loadModel()\n",
        "face_detector = MTCNN()"
      ],
      "metadata": {
        "id": "W-y6jNmd81H3",
        "outputId": "7ec8e69f-00e4-4f81-cdd6-16afc52d1c74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arcface_weights.h5  will be downloaded to  /root/.deepface/weights/arcface_weights.h5\n",
            "Access denied with the following error:\n",
            "pre-trained weights could not be loaded.\n",
            "You might try to download it from the url  https://drive.google.com/uc?id=1LVB3CdVejpmGHM28BpqqkbZP5hDEcdZY  and copy to  /root/.deepface/weights/arcface_weights.h5  manually\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1LVB3CdVejpmGHM28BpqqkbZP5hDEcdZY \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_face(img):\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #mtcnn expects RGB but OpenCV read BGR\n",
        "    detections = face_detector.detect_faces(img_rgb)\n",
        "    detection = detections[0]\n",
        "    x, y, w, h = detection[\"box\"]\n",
        "    detected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
        "    return detected_face"
      ],
      "metadata": {
        "id": "AY0cZQDa9K9e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_face(img, target_size=(112,112)):\n",
        "    img = cv2.imread(img)\n",
        "    img = detect_face(img)\n",
        "    img = cv2.resize(img, target_size)\n",
        "    img_pixels = image.img_to_array(img)\n",
        "    img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "    img_pixels /= 255 #normalize input in [0, 1]\n",
        "    return img_pixels"
      ],
      "metadata": {
        "id": "k4mCAfBh9NHm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_to_encoding(path):\n",
        "    img = preprocess_face(path)\n",
        "    return model.predict(img)[0]"
      ],
      "metadata": {
        "id": "lxywHjsj9OuN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo5.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "A1UQ1FLn9SgU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "\n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "1SpJ3Xgh9eWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "database = {}\n",
        "database[\"person1\"] = img_to_encoding(\"photo_1.jpg\")\n",
        "database[\"person2\"] = img_to_encoding(\"photo_2.jpg\")\n",
        "database[\"person3\"] = img_to_encoding(\"photo_3.jpg\")\n",
        "database[\"person4\"] = img_to_encoding(\"photo_4.jpg\")\n",
        "database[\"person5\"] = img_to_encoding(\"photo_5.jpg\")"
      ],
      "metadata": {
        "id": "IPtCziPw9Qnl",
        "outputId": "7c83ce41-c9b0-4a5a-b879-431eb8cf0c73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 211ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 220ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3/3 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 386ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 226ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def EuclideanDistance(source_representation, test_representation):\n",
        "    euclidean_distance = source_representation - test_representation\n",
        "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
        "    euclidean_distance = np.sqrt(euclidean_distance)\n",
        "    return euclidean_distance"
      ],
      "metadata": {
        "id": "viyEEzmN94er"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verification_threshhold = 8"
      ],
      "metadata": {
        "id": "2RC-oAmH97Aj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify(image_path, identity, database):\n",
        "    # Step 1: Compute the encoding for the image. Use img_to_encoding()\n",
        "    encoding = img_to_encoding(image_path)\n",
        "\n",
        "    # Step 2: Compute distance with identity's image\n",
        "    dist = EuclideanDistance(encoding, database[identity])\n",
        "\n",
        "    # Step 3: Open the door if dist < verification_threshhold, else don't open\n",
        "    if dist < verification_threshhold:\n",
        "        print(\"It's \" + str(identity) + \", welcome!\")\n",
        "    else:\n",
        "        print(\"It's not \" + str(identity) + \", please go away\")\n",
        "\n",
        "    return dist"
      ],
      "metadata": {
        "id": "JRsYizJl9-8z"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verify(\"b3.jpg\", \"mohammadreza\", database)"
      ],
      "metadata": {
        "id": "v76ufVrO-Cdi",
        "outputId": "070e3cce-46cb-4faa-c4b4-c088c0d93720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 237ms/step\n",
            "It's not mohammadreza, please go away\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.624786"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def who_is_it(image_path, database):\n",
        "\n",
        "    ## Step 1: Compute the target \"encoding\" for the image. Use img_to_encoding()\n",
        "    encoding = img_to_encoding(image_path)\n",
        "\n",
        "    ## Step 2: Find the closest encoding ##\n",
        "\n",
        "    # Initialize \"min_dist\" to a large value, say 100\n",
        "    min_dist = 1000\n",
        "    # Loop over the database dictionary's names and encodings.\n",
        "    for (name, db_enc) in database.items():\n",
        "        # Compute L2 distance between the target \"encoding\" and the current \"emb\" from the database. (≈ 1 line)\n",
        "        dist = EuclideanDistance(encoding, db_enc)\n",
        "\n",
        "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)\n",
        "        if min_dist > dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "\n",
        "\n",
        "    if min_dist > verification_threshhold:\n",
        "        print(\"Not in the database.\")\n",
        "    else:\n",
        "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
        "\n",
        "    return min_dist, identity"
      ],
      "metadata": {
        "id": "meXxsY_G-EbI"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "who_is_it(\"b.jpg\", database)"
      ],
      "metadata": {
        "id": "jOKpiHVr-P4E",
        "outputId": "b2e2d1c3-0d6b-40ae-ab42-041ad2a54ee4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 223ms/step\n",
            "Not in the database.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.268738, 'mohammadreza')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}